{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 1: Setup & Configuration"
      ],
      "metadata": {
        "id": "ZVJwyGZLbQqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Import libraries and functions\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
        "from keras.layers import Input, LSTM, Concatenate, RepeatVector, Permute, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Configuration class\n",
        "class Config:\n",
        "    \"\"\"Configuration parameters for the CVD prediction experiment.\"\"\"\n",
        "    DATA_PATH = \"Dataset.csv\"\n",
        "    TARGET_COL = 'target'\n",
        "    CATEGORICAL_COLS = ['chest pain type', 'resting ecg', 'ST slope']\n",
        "\n",
        "    # Model parameters\n",
        "    RANDOM_STATE = 42\n",
        "    N_SPLITS = 5\n",
        "    EPOCHS = 100\n",
        "    CNN_BATCH_SIZE = 16\n",
        "    LSTM_BATCH_SIZE = 32\n",
        "    CNN_LEARNING_RATE = 0.0001\n",
        "    LSTM_LEARNING_RATE = 0.001\n",
        "\n",
        "    # Model architecture\n",
        "    CNN_FILTERS = [64, 128, 256]\n",
        "    CNN_KERNEL_SIZES = [5, 3, 1]\n",
        "    LSTM_UNITS = [256, 128]\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(Config.RANDOM_STATE)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(Config.RANDOM_STATE)\n",
        "\n",
        "print(\"Setup complete. Configuration loaded.\")"
      ],
      "metadata": {
        "id": "Fg5AA2ObR-SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 2: Data Loading & Exploration"
      ],
      "metadata": {
        "id": "DTRwwl-aSK8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading dataset...\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(Config.DATA_PATH)\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Features: {df.columns.tolist()}\")\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\nDataset Overview:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Total samples: {len(df)}\")\n",
        "print(f\"Number of features: {len(df.columns) - 1}\")  # Excluding target\n",
        "print(f\"Target variable: '{Config.TARGET_COL}'\")\n",
        "print(f\"Missing values: {df.isnull().sum().sum()}\")\n",
        "\n",
        "# Target distribution\n",
        "target_counts = df[Config.TARGET_COL].value_counts()\n",
        "print(f\"\\nTarget Distribution:\")\n",
        "print(f\"  Class 0 (No CVD): {target_counts.get(0, 0)} samples ({target_counts.get(0, 0)/len(df)*100:.1f}%)\")\n",
        "print(f\"  Class 1 (CVD): {target_counts.get(1, 0)} samples ({target_counts.get(1, 0)/len(df)*100:.1f}%)\")\n",
        "\n",
        "# Display first few rows\n",
        "print(\"\\nData Preview (first 5 rows):\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nData loading complete.\")"
      ],
      "metadata": {
        "id": "wUwVFCxHSLJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 3: Data Preprocessing Pipeline"
      ],
      "metadata": {
        "id": "B-asjRHMSXGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(df):\n",
        "    \"\"\"\n",
        "    Preprocess the cardiovascular disease dataset.\n",
        "\n",
        "    Steps:\n",
        "    1. Remove null values\n",
        "    2. Standard scale numerical features\n",
        "    3. Remove outliers using Z-score method\n",
        "    4. One-hot encode categorical variables\n",
        "    5. Separate features and target\n",
        "\n",
        "    Returns:\n",
        "        X (DataFrame): Preprocessed features\n",
        "        y (Series): Target variable\n",
        "        df_encoded (DataFrame): Fully processed dataframe\n",
        "    \"\"\"\n",
        "    print(\"Starting data preprocessing...\")\n",
        "\n",
        "    # Step 1: Remove null values\n",
        "    initial_count = len(df)\n",
        "    df_clean = df.dropna().reset_index(drop=True)\n",
        "    print(f\"   Removed {initial_count - len(df_clean)} records with null values\")\n",
        "\n",
        "    # Step 2: Standard scaling (Z-score normalization)\n",
        "    scaler = StandardScaler()\n",
        "    numerical_cols = [col for col in df_clean.columns\n",
        "                     if col not in Config.CATEGORICAL_COLS + [Config.TARGET_COL]]\n",
        "\n",
        "    if numerical_cols:\n",
        "        df_clean[numerical_cols] = scaler.fit_transform(df_clean[numerical_cols])\n",
        "        print(f\"  Scaled {len(numerical_cols)} numerical features\")\n",
        "\n",
        "    # Step 3: Outlier detection and removal (Z-score > 3)\n",
        "    z_scores = (df_clean.select_dtypes(include=[np.number]) -\n",
        "                df_clean.select_dtypes(include=[np.number]).mean()) / \\\n",
        "               df_clean.select_dtypes(include=[np.number]).std()\n",
        "\n",
        "    outliers = (z_scores > 3) | (z_scores < -3)\n",
        "    df_no_outliers = df_clean[~outliers.any(axis=1)].reset_index(drop=True)\n",
        "    print(f\"  Removed {len(df_clean) - len(df_no_outliers)} outliers (|Z| > 3)\")\n",
        "\n",
        "    # Step 4: One-hot encoding for categorical variables\n",
        "    df_encoded = pd.get_dummies(df_no_outliers, columns=Config.CATEGORICAL_COLS)\n",
        "    print(f\"  One-hot encoded {len(Config.CATEGORICAL_COLS)} categorical variables\")\n",
        "\n",
        "    # Step 5: Separate features and target\n",
        "    X = df_encoded.drop(Config.TARGET_COL, axis=1)\n",
        "    y = df_encoded[Config.TARGET_COL]\n",
        "\n",
        "    print(f\"  Final shape: {X.shape[0]} samples, {X.shape[1]} features\")\n",
        "    print(\"Preprocessing complete.\")\n",
        "\n",
        "    return X, y, df_encoded\n",
        "\n",
        "# Apply preprocessing\n",
        "X, y, df_processed = preprocess_data(df)\n",
        "\n",
        "# Display processed data info\n",
        "print(f\"\\nProcessed Data Summary:\")\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Feature names: {list(X.columns[:5])}...\" if len(X.columns) > 5 else list(X.columns))"
      ],
      "metadata": {
        "id": "rgYvM8LwSXR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 4: Data Balancing with SMOTE"
      ],
      "metadata": {
        "id": "x9pydjrESnfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_smote_balancing(X, y):\n",
        "    \"\"\"\n",
        "    Apply SMOTE to balance the dataset.\n",
        "\n",
        "    Args:\n",
        "        X: Features\n",
        "        y: Target variable\n",
        "\n",
        "    Returns:\n",
        "        X_balanced: Balanced features (as numpy array)\n",
        "        y_balanced: Balanced target (as numpy array)\n",
        "    \"\"\"\n",
        "    print(\"\\nApplying SMOTE for class balancing...\")\n",
        "\n",
        "    # Check initial class distribution\n",
        "    unique, counts = np.unique(y, return_counts=True)\n",
        "    print(f\"  Initial class distribution:\")\n",
        "    for cls, count in zip(unique, counts):\n",
        "        print(f\"    Class {cls}: {count} samples ({count/len(y)*100:.1f}%)\")\n",
        "\n",
        "    # Apply SMOTE\n",
        "    smote = SMOTE(random_state=Config.RANDOM_STATE)\n",
        "    X_balanced, y_balanced = smote.fit_resample(X, y)\n",
        "\n",
        "    #Convert to numpy arrays with consistent dtype\n",
        "    X_balanced = np.array(X_balanced, dtype=np.float32)\n",
        "    y_balanced = np.array(y_balanced, dtype=np.float32)\n",
        "\n",
        "    # Check balanced class distribution\n",
        "    unique_bal, counts_bal = np.unique(y_balanced, return_counts=True)\n",
        "    print(f\"\\n  After SMOTE balancing:\")\n",
        "    for cls, count in zip(unique_bal, counts_bal):\n",
        "        print(f\"    Class {cls}: {count} samples ({count/len(y_balanced)*100:.1f}%)\")\n",
        "\n",
        "    print(f\"\\nBalancing complete. New shape: {X_balanced.shape}\")\n",
        "\n",
        "    return X_balanced, y_balanced\n",
        "\n",
        "# Apply SMOTE balancing\n",
        "X_balanced, y_balanced = apply_smote_balancing(X, y)"
      ],
      "metadata": {
        "id": "o6PopSh9Snvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 5: CNN Model Definition & Training"
      ],
      "metadata": {
        "id": "oqvqEkT8Sv-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model(input_shape):\n",
        "    \"\"\"\n",
        "    Create a 1D CNN model for binary classification.\n",
        "\n",
        "    Architecture:\n",
        "    - Three Conv1D layers with increasing filters\n",
        "    - MaxPooling after each convolutional layer\n",
        "    - Fully connected layers with dropout for regularization\n",
        "    - Sigmoid output for binary classification\n",
        "\n",
        "    Args:\n",
        "        input_shape: Number of features in input data\n",
        "\n",
        "    Returns:\n",
        "        model: Compiled CNN model\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        # First convolutional block\n",
        "        Conv1D(filters=Config.CNN_FILTERS[0], kernel_size=Config.CNN_KERNEL_SIZES[0],\n",
        "               activation='relu', input_shape=(input_shape, 1)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        # Second convolutional block\n",
        "        Conv1D(filters=Config.CNN_FILTERS[1], kernel_size=Config.CNN_KERNEL_SIZES[1],\n",
        "               activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        # Third convolutional block\n",
        "        Conv1D(filters=Config.CNN_FILTERS[2], kernel_size=Config.CNN_KERNEL_SIZES[2],\n",
        "               activation='relu'),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        # Flatten and fully connected layers\n",
        "        Flatten(),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "\n",
        "        # Output layer\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # Compile model\n",
        "    optimizer = Adam(learning_rate=Config.CNN_LEARNING_RATE)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_cnn_model(X, y):\n",
        "    \"\"\"\n",
        "    Train CNN model using 5-fold cross-validation.\n",
        "\n",
        "    Args:\n",
        "        X: Features\n",
        "        y: Target variable\n",
        "\n",
        "    Returns:\n",
        "        results_dict: Dictionary containing evaluation metrics\n",
        "        histories: Training history for each fold\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING CNN MODEL (5-Fold Cross-Validation)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    X_array = np.array(X)\n",
        "    y_array = np.array(y)\n",
        "\n",
        "    # Initialize results storage\n",
        "    results_dict = {\n",
        "        'fold': [], 'accuracy': [], 'precision': [],\n",
        "        'recall': [], 'f1': [], 'loss': []\n",
        "    }\n",
        "    histories = []\n",
        "\n",
        "    # Setup cross-validation\n",
        "    skf = StratifiedKFold(n_splits=Config.N_SPLITS,\n",
        "                          shuffle=True,\n",
        "                          random_state=Config.RANDOM_STATE)\n",
        "\n",
        "    # Setup visualization\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
        "    plt.suptitle('CNN Model: Training Progress (5-Fold CV)', fontsize=14, y=1.02)\n",
        "\n",
        "    # Cross-validation loop\n",
        "    for fold, (train_idx, test_idx) in enumerate(skf.split(X_array, y_array), 1):\n",
        "        print(f\"\\nFold {fold}/{Config.N_SPLITS}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test = X_array[train_idx], X_array[test_idx]\n",
        "        y_train, y_test = y_array[train_idx], y_array[test_idx]\n",
        "\n",
        "        # Reshape for CNN (add channel dimension)\n",
        "        X_train_cnn = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "        X_test_cnn = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "        # Convert to float32\n",
        "        X_train_cnn = X_train_cnn.astype('float32')\n",
        "        X_test_cnn = X_test_cnn.astype('float32')\n",
        "\n",
        "        # Create and train model\n",
        "        model = create_cnn_model(X_train_cnn.shape[1])\n",
        "        history = model.fit(\n",
        "            X_train_cnn, y_train,\n",
        "            epochs=Config.EPOCHS,\n",
        "            batch_size=Config.CNN_BATCH_SIZE,\n",
        "            validation_data=(X_test_cnn, y_test),\n",
        "            verbose=0\n",
        "        )\n",
        "        histories.append(history)\n",
        "\n",
        "        # Plot training curves\n",
        "        axes[0].plot(history.history['accuracy'],\n",
        "                    label=f'Fold {fold} Train', alpha=0.7, linewidth=1)\n",
        "        axes[0].plot(history.history['val_accuracy'],\n",
        "                    label=f'Fold {fold} Val', alpha=0.7, linewidth=1, linestyle='--')\n",
        "\n",
        "        axes[1].plot(history.history['loss'],\n",
        "                    label=f'Fold {fold} Train', alpha=0.7, linewidth=1)\n",
        "        axes[1].plot(history.history['val_loss'],\n",
        "                    label=f'Fold {fold} Val', alpha=0.7, linewidth=1, linestyle='--')\n",
        "\n",
        "        # Evaluate model\n",
        "        y_pred = np.round(model.predict(X_test_cnn, verbose=0)).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred)\n",
        "        recall = recall_score(y_test, y_pred)\n",
        "        f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "        # Store results\n",
        "        results_dict['fold'].append(fold)\n",
        "        results_dict['accuracy'].append(accuracy)\n",
        "        results_dict['precision'].append(precision)\n",
        "        results_dict['recall'].append(recall)\n",
        "        results_dict['f1'].append(f1)\n",
        "        results_dict['loss'].append(history.history['val_loss'][-1])\n",
        "\n",
        "        # Print fold results\n",
        "        print(f\"  Accuracy:  {accuracy:.3f}\")\n",
        "        print(f\"  Precision: {precision:.3f}\")\n",
        "        print(f\"  Recall:    {recall:.3f}\")\n",
        "        print(f\"  F1-Score:  {f1:.3f}\")\n",
        "\n",
        "    # Configure plots\n",
        "    axes[0].set_title('Model Accuracy', fontsize=12)\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].legend(loc='lower right', fontsize=9)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].set_title('Model Loss', fontsize=12)\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend(loc='upper right', fontsize=9)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print average results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CNN MODEL - AVERAGE RESULTS (5-Fold CV)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Average Accuracy:  {np.mean(results_dict['accuracy']):.3f}\")\n",
        "    print(f\"Average Precision: {np.mean(results_dict['precision']):.3f}\")\n",
        "    print(f\"Average Recall:    {np.mean(results_dict['recall']):.3f}\")\n",
        "    print(f\"Average F1-Score:  {np.mean(results_dict['f1']):.3f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return results_dict, histories\n",
        "\n",
        "# Train CNN model\n",
        "cnn_results, cnn_histories = train_cnn_model(X_balanced, y_balanced)"
      ],
      "metadata": {
        "id": "AFUcQiLBSwHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 6: LSTM Model Definition & Training"
      ],
      "metadata": {
        "id": "b22aCW4TS8EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_lstm_model(input_shape, dropout_rate=0.3):\n",
        "    \"\"\"\n",
        "    Create an LSTM model with attention mechanism for binary classification.\n",
        "\n",
        "    Architecture:\n",
        "    - LSTM layer with dropout and batch normalization\n",
        "    - Attention mechanism to weight important features\n",
        "    - Second LSTM layer for sequence processing\n",
        "    - Sigmoid output for binary classification\n",
        "\n",
        "    Args:\n",
        "        input_shape: Number of features in input data\n",
        "        dropout_rate: Dropout rate for regularization\n",
        "\n",
        "    Returns:\n",
        "        model: Compiled LSTM model\n",
        "    \"\"\"\n",
        "    # Input layer\n",
        "    inputs = Input(shape=(1, input_shape))\n",
        "\n",
        "    # First LSTM layer with regularization\n",
        "    lstm_out = LSTM(Config.LSTM_UNITS[0], return_sequences=True)(inputs)\n",
        "    lstm_out = Dropout(dropout_rate)(lstm_out)\n",
        "    lstm_out = BatchNormalization()(lstm_out)\n",
        "\n",
        "    # Attention mechanism\n",
        "    attention = Dense(1, activation='tanh')(lstm_out)\n",
        "    attention = Flatten()(attention)\n",
        "    attention = RepeatVector(input_shape)(attention)\n",
        "    attention = Permute((2, 1))(attention)\n",
        "\n",
        "    # Apply attention and second LSTM\n",
        "    attention_out = Concatenate(axis=-1)([lstm_out, attention])\n",
        "    attention_out = LSTM(Config.LSTM_UNITS[1])(attention_out)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(1, activation='sigmoid')(attention_out)\n",
        "\n",
        "    # Create and compile model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    optimizer = Adam(learning_rate=Config.LSTM_LEARNING_RATE)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_lstm_model(X, y):\n",
        "    \"\"\"\n",
        "    Train LSTM model using 5-fold cross-validation.\n",
        "\n",
        "    Args:\n",
        "        X: Features (must be numpy array)\n",
        "        y: Target variable (must be numpy array)\n",
        "\n",
        "    Returns:\n",
        "        results_dict: Dictionary containing evaluation metrics\n",
        "        histories: Training history for each fold\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"TRAINING LSTM MODEL (5-Fold Cross-Validation)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # CRITICAL FIX: Ensure data is in correct format\n",
        "    # Convert to numpy arrays with explicit float32 dtype\n",
        "    X_array = np.array(X, dtype=np.float32)\n",
        "    y_array = np.array(y, dtype=np.float32)\n",
        "\n",
        "    # Validate data types\n",
        "    print(f\"Data type check:\")\n",
        "    print(f\"  X_array dtype: {X_array.dtype}, shape: {X_array.shape}\")\n",
        "    print(f\"  y_array dtype: {y_array.dtype}, shape: {y_array.shape}\")\n",
        "\n",
        "    # Check for any non-numeric values\n",
        "    if np.isnan(X_array).any():\n",
        "        print(\"  Warning: X_array contains NaN values\")\n",
        "        X_array = np.nan_to_num(X_array)  # Replace NaN with 0\n",
        "\n",
        "    # Initialize results storage\n",
        "    results_dict = {\n",
        "        'fold': [], 'accuracy': [], 'precision': [],\n",
        "        'recall': [], 'f1': [], 'loss': []\n",
        "    }\n",
        "    histories = []\n",
        "\n",
        "    # Setup cross-validation\n",
        "    kf = KFold(n_splits=Config.N_SPLITS,\n",
        "               shuffle=True,\n",
        "               random_state=Config.RANDOM_STATE)\n",
        "\n",
        "    # Setup visualization\n",
        "    fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
        "    plt.suptitle('LSTM Model: Training Progress (5-Fold CV)', fontsize=14, y=1.02)\n",
        "\n",
        "    # Cross-validation loop\n",
        "    for fold, (train_idx, test_idx) in enumerate(kf.split(X_array), 1):\n",
        "        print(f\"\\nFold {fold}/{Config.N_SPLITS}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test = X_array[train_idx], X_array[test_idx]\n",
        "        y_train, y_test = y_array[train_idx], y_array[test_idx]\n",
        "\n",
        "        # Reshape for LSTM (add timestep dimension)\n",
        "        X_train_lstm = X_train.reshape(-1, 1, X_train.shape[1]).astype(np.float32)\n",
        "        X_test_lstm = X_test.reshape(-1, 1, X_test.shape[1]).astype(np.float32)\n",
        "\n",
        "        print(f\"  Training set shape: {X_train_lstm.shape}\")\n",
        "        print(f\"  Test set shape: {X_test_lstm.shape}\")\n",
        "\n",
        "        # Create and train model\n",
        "        model = create_lstm_model(X_train.shape[1])\n",
        "        history = model.fit(\n",
        "            X_train_lstm, y_train,\n",
        "            epochs=Config.EPOCHS,\n",
        "            batch_size=Config.LSTM_BATCH_SIZE,\n",
        "            validation_data=(X_test_lstm, y_test),\n",
        "            verbose=0\n",
        "        )\n",
        "        histories.append(history)\n",
        "\n",
        "        # Plot training curves\n",
        "        axes[0].plot(history.history['accuracy'],\n",
        "                    label=f'Fold {fold} Train', alpha=0.7, linewidth=1)\n",
        "        axes[0].plot(history.history['val_accuracy'],\n",
        "                    label=f'Fold {fold} Val', alpha=0.7, linewidth=1, linestyle='--')\n",
        "\n",
        "        axes[1].plot(history.history['loss'],\n",
        "                    label=f'Fold {fold} Train', alpha=0.7, linewidth=1)\n",
        "        axes[1].plot(history.history['val_loss'],\n",
        "                    label=f'Fold {fold} Val', alpha=0.7, linewidth=1, linestyle='--')\n",
        "\n",
        "        # Evaluate model\n",
        "        y_pred = model.predict(X_test_lstm, verbose=0)\n",
        "        y_pred_class = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred_class)\n",
        "        precision = precision_score(y_test, y_pred_class)\n",
        "        recall = recall_score(y_test, y_pred_class)\n",
        "        f1 = f1_score(y_test, y_pred_class)\n",
        "\n",
        "        # Store results\n",
        "        results_dict['fold'].append(fold)\n",
        "        results_dict['accuracy'].append(accuracy)\n",
        "        results_dict['precision'].append(precision)\n",
        "        results_dict['recall'].append(recall)\n",
        "        results_dict['f1'].append(f1)\n",
        "        results_dict['loss'].append(history.history['val_loss'][-1])\n",
        "\n",
        "        # Print fold results\n",
        "        print(f\"  Accuracy:  {accuracy:.3f}\")\n",
        "        print(f\"  Precision: {precision:.3f}\")\n",
        "        print(f\"  Recall:    {recall:.3f}\")\n",
        "        print(f\"  F1-Score:  {f1:.3f}\")\n",
        "\n",
        "    # Configure plots\n",
        "    axes[0].set_title('Model Accuracy', fontsize=12)\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Accuracy')\n",
        "    axes[0].legend(loc='lower right', fontsize=9)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].set_title('Model Loss', fontsize=12)\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Loss')\n",
        "    axes[1].legend(loc='upper right', fontsize=9)\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print average results\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"LSTM MODEL - AVERAGE RESULTS (5-Fold CV)\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"Average Accuracy:  {np.mean(results_dict['accuracy']):.3f}\")\n",
        "    print(f\"Average Precision: {np.mean(results_dict['precision']):.3f}\")\n",
        "    print(f\"Average Recall:    {np.mean(results_dict['recall']):.3f}\")\n",
        "    print(f\"Average F1-Score:  {np.mean(results_dict['f1']):.3f}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    return results_dict, histories\n",
        "\n",
        "# Train LSTM model - FIXED: Ensure data is numpy array before passing\n",
        "lstm_results, lstm_histories = train_lstm_model(np.array(X_balanced), np.array(y_balanced))"
      ],
      "metadata": {
        "id": "1t_mYNMYS8Ou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BLOCK 7: Results Comparison"
      ],
      "metadata": {
        "id": "YkXG3TvtTLwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_results(cnn_results, lstm_results):\n",
        "    \"\"\"\n",
        "    Compare CNN and LSTM results and generate visualizations.\n",
        "\n",
        "    Args:\n",
        "        cnn_results: Results dictionary from CNN model\n",
        "        lstm_results: Results dictionary from LSTM model\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"MODEL COMPARISON: CNN vs LSTM\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Calculate average metrics\n",
        "    cnn_avg = {\n",
        "        'accuracy': np.mean(cnn_results['accuracy']),\n",
        "        'precision': np.mean(cnn_results['precision']),\n",
        "        'recall': np.mean(cnn_results['recall']),\n",
        "        'f1': np.mean(cnn_results['f1'])\n",
        "    }\n",
        "\n",
        "    lstm_avg = {\n",
        "        'accuracy': np.mean(lstm_results['accuracy']),\n",
        "        'precision': np.mean(lstm_results['precision']),\n",
        "        'recall': np.mean(lstm_results['recall']),\n",
        "        'f1': np.mean(lstm_results['f1'])\n",
        "    }\n",
        "\n",
        "    # Create comparison table\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': ['CNN', 'LSTM'],\n",
        "        'Accuracy': [cnn_avg['accuracy'], lstm_avg['accuracy']],\n",
        "        'Precision': [cnn_avg['precision'], lstm_avg['precision']],\n",
        "        'Recall': [cnn_avg['recall'], lstm_avg['recall']],\n",
        "        'F1-Score': [cnn_avg['f1'], lstm_avg['f1']]\n",
        "    })\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\nAverage Performance Metrics:\")\n",
        "    print(\"-\" * 65)\n",
        "    print(comparison_df.to_string(index=False))\n",
        "    print(\"-\" * 65)\n",
        "\n",
        "    # Visualizations\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "    plt.suptitle('CNN vs LSTM: Performance Comparison', fontsize=16, y=1.02)\n",
        "\n",
        "    # Plot 1: Accuracy comparison across folds\n",
        "    axes[0, 0].plot(cnn_results['fold'], cnn_results['accuracy'],\n",
        "                   'o-', label='CNN', linewidth=2, markersize=8)\n",
        "    axes[0, 0].plot(lstm_results['fold'], lstm_results['accuracy'],\n",
        "                   's--', label='LSTM', linewidth=2, markersize=8)\n",
        "    axes[0, 0].set_title('Accuracy by Fold', fontsize=12)\n",
        "    axes[0, 0].set_xlabel('Fold')\n",
        "    axes[0, 0].set_ylabel('Accuracy')\n",
        "    axes[0, 0].legend()\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: F1-Score comparison across folds\n",
        "    axes[0, 1].plot(cnn_results['fold'], cnn_results['f1'],\n",
        "                   'o-', label='CNN', linewidth=2, markersize=8)\n",
        "    axes[0, 1].plot(lstm_results['fold'], lstm_results['f1'],\n",
        "                   's--', label='LSTM', linewidth=2, markersize=8)\n",
        "    axes[0, 1].set_title('F1-Score by Fold', fontsize=12)\n",
        "    axes[0, 1].set_xlabel('Fold')\n",
        "    axes[0, 1].set_ylabel('F1-Score')\n",
        "    axes[0, 1].legend()\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 3: Bar chart of average metrics\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    cnn_vals = [cnn_avg['accuracy'], cnn_avg['precision'],\n",
        "                cnn_avg['recall'], cnn_avg['f1']]\n",
        "    lstm_vals = [lstm_avg['accuracy'], lstm_avg['precision'],\n",
        "                 lstm_avg['recall'], lstm_avg['f1']]\n",
        "\n",
        "    x = np.arange(len(metrics))\n",
        "    width = 0.35\n",
        "\n",
        "    axes[1, 0].bar(x - width/2, cnn_vals, width, label='CNN', alpha=0.8)\n",
        "    axes[1, 0].bar(x + width/2, lstm_vals, width, label='LSTM', alpha=0.8)\n",
        "    axes[1, 0].set_title('Average Performance Metrics', fontsize=12)\n",
        "    axes[1, 0].set_xlabel('Metric')\n",
        "    axes[1, 0].set_ylabel('Score')\n",
        "    axes[1, 0].set_xticks(x)\n",
        "    axes[1, 0].set_xticklabels(metrics)\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Plot 4: Performance difference (LSTM - CNN)\n",
        "    performance_diff = {\n",
        "        'Accuracy': lstm_avg['accuracy'] - cnn_avg['accuracy'],\n",
        "        'Precision': lstm_avg['precision'] - cnn_avg['precision'],\n",
        "        'Recall': lstm_avg['recall'] - cnn_avg['recall'],\n",
        "        'F1-Score': lstm_avg['f1'] - cnn_avg['f1']\n",
        "    }\n",
        "\n",
        "    # Determine bar colors (green if positive, red if negative)\n",
        "    colors = ['green' if val > 0 else 'red' for val in performance_diff.values()]\n",
        "\n",
        "    axes[1, 1].bar(metrics, list(performance_diff.values()), color=colors, alpha=0.7)\n",
        "    axes[1, 1].axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
        "    axes[1, 1].set_title('Performance Difference: LSTM - CNN', fontsize=12)\n",
        "    axes[1, 1].set_xlabel('Metric')\n",
        "    axes[1, 1].set_ylabel('Difference (LSTM - CNN)')\n",
        "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(performance_diff.values()):\n",
        "        axes[1, 1].text(i, v + (0.01 if v >= 0 else -0.02),\n",
        "                       f'{v:.3f}', ha='center', va='bottom' if v >= 0 else 'top')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print summary insights\n",
        "    print(\"\\nKEY INSIGHTS:\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    # Determine best model based on accuracy\n",
        "    if lstm_avg['accuracy'] > cnn_avg['accuracy']:\n",
        "        accuracy_diff = lstm_avg['accuracy'] - cnn_avg['accuracy']\n",
        "        print(f\"• LSTM has higher accuracy by {accuracy_diff:.3f}\")\n",
        "        best_model_accuracy = \"LSTM\"\n",
        "    elif cnn_avg['accuracy'] > lstm_avg['accuracy']:\n",
        "        accuracy_diff = cnn_avg['accuracy'] - lstm_avg['accuracy']\n",
        "        print(f\"• CNN has higher accuracy by {accuracy_diff:.3f}\")\n",
        "        best_model_accuracy = \"CNN\"\n",
        "    else:\n",
        "        print(\"• Both models have equal accuracy\")\n",
        "        best_model_accuracy = \"Tie\"\n",
        "\n",
        "    # Determine best model based on F1-Score\n",
        "    if lstm_avg['f1'] > cnn_avg['f1']:\n",
        "        f1_diff = lstm_avg['f1'] - cnn_avg['f1']\n",
        "        print(f\"• LSTM has higher F1-Score by {f1_diff:.3f}\")\n",
        "        best_model_f1 = \"LSTM\"\n",
        "    elif cnn_avg['f1'] > lstm_avg['f1']:\n",
        "        f1_diff = cnn_avg['f1'] - lstm_avg['f1']\n",
        "        print(f\"• CNN has higher F1-Score by {f1_diff:.3f}\")\n",
        "        best_model_f1 = \"CNN\"\n",
        "    else:\n",
        "        print(\"• Both models have equal F1-Score\")\n",
        "        best_model_f1 = \"Tie\"\n",
        "\n",
        "    # Check consistency across folds\n",
        "    cnn_std = np.std(cnn_results['accuracy'])\n",
        "    lstm_std = np.std(lstm_results['accuracy'])\n",
        "\n",
        "    print(f\"\\nModel Stability (Lower STD = More Consistent):\")\n",
        "    print(f\"   CNN Accuracy STD:  {cnn_std:.4f}\")\n",
        "    print(f\"   LSTM Accuracy STD: {lstm_std:.4f}\")\n",
        "\n",
        "    if cnn_std < lstm_std:\n",
        "        print(\"   • CNN shows more consistent performance across folds\")\n",
        "    elif lstm_std < cnn_std:\n",
        "        print(\"   • LSTM shows more consistent performance across folds\")\n",
        "    else:\n",
        "        print(\"   • Both models show equal consistency\")\n",
        "\n",
        "\n",
        "# Compare results\n",
        "compare_results(cnn_results, lstm_results)\n",
        "print(\"\\n\" + \"=\"*60)"
      ],
      "metadata": {
        "id": "jjZydaI8TLKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}